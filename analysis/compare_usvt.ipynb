{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!hostname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# import torchvision.models as models\n",
    "import torch.distributed as dist\n",
    "# import torch.optim as optim\n",
    "import scipy.stats as stats\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from rich.progress import track\n",
    "\n",
    "\n",
    "# # oialr_checkpoint_folder = \"/hkfs/work/workspace/scratch/qv2382-madonna/madonna/models/svd-final/12/weights/epoch_299.pt\"\n",
    "# oialr_checkpoint_folder = \"/hkfs/work/workspace/scratch/qv2382-madonna-ddp/madonna/models/svd-nodroppath/2/weights/epoch_299.pt\"\n",
    "# # baseline_checkpoint_folder = \"/hkfs/work/workspace/scratch/qv2382-madonna/madonna/models/baseline-final/8/weights/epoch_299.pt\"\n",
    "# baseline_checkpoint_folder = \"/hkfs/work/workspace/scratch/qv2382-madonna-ddp/madonna/models/baseline-nodroppath/1/weights/epoch_299.pt\"\n",
    "\n",
    "checkpoints = {}\n",
    "# ortho-sigma\n",
    "# /hkfs/work/workspace/scratch/qv2382-madonna-ddp/madonna/models/fed-debug/42/weights3\n",
    "# /hkfs/work/workspace/scratch/qv2382-madonna-ddp/madonna/models/fed-debug/42/weights2\n",
    "# /hkfs/work/workspace/scratch/qv2382-madonna-ddp/madonna/models/fed-debug/43/weights1\n",
    "# /hkfs/work/workspace/scratch/qv2382-madonna-ddp/madonna/models/fed-debug/44/weights0\n",
    "# checkpoints[\"ortho-sigma\"] = {\n",
    "#     0: Path(\"/hkfs/work/workspace/scratch/qv2382-madonna-ddp/madonna/models/fed-debug/44/weights0\"),\n",
    "#     1: Path(\"/hkfs/work/workspace/scratch/qv2382-madonna-ddp/madonna/models/fed-debug/43/weights1\"),\n",
    "#     2: Path(\"/hkfs/work/workspace/scratch/qv2382-madonna-ddp/madonna/models/fed-debug/42/weights2\"),\n",
    "#     3: Path(\"/hkfs/work/workspace/scratch/qv2382-madonna-ddp/madonna/models/fed-debug/42/weights3\"),\n",
    "# }\n",
    "\n",
    "# checkpoints[\"rand-sigma\"] = {\n",
    "#     0: Path(\"/hkfs/work/workspace/scratch/qv2382-madonna-ddp/madonna/models/fed-debug-randsigma/0/weights0\"),\n",
    "#     1: Path(\"/hkfs/work/workspace/scratch/qv2382-madonna-ddp/madonna/models/fed-debug-randsigma/1/weights1\"),\n",
    "#     2: Path(\"/hkfs/work/workspace/scratch/qv2382-madonna-ddp/madonna/models/fed-debug-randsigma/2/weights2\"),\n",
    "#     3: Path(\"/hkfs/work/workspace/scratch/qv2382-madonna-ddp/madonna/models/fed-debug-randsigma/0/weights3\"),\n",
    "# }\n",
    "\n",
    "# checkpoints_resnet18 = {}\n",
    "# checkpoints_resnet18[\"ortho-sigma\"] = {\n",
    "#     3: Path(\"/hkfs/work/workspace/scratch/qv2382-madonna-ddp/madonna/models/fed-orthosigma/9/weights3\"),\n",
    "#     0: Path(\"/hkfs/work/workspace/scratch/qv2382-madonna-ddp/madonna/models/fed-orthosigma/10/weights0\"),\n",
    "#     1: Path(\"/hkfs/work/workspace/scratch/qv2382-madonna-ddp/madonna/models/fed-orthosigma/11/weights1\"),\n",
    "#     2: Path(\"/hkfs/work/workspace/scratch/qv2382-madonna-ddp/madonna/models/fed-orthosigma/12/weights2\"),\n",
    "# }\n",
    "\n",
    "# checkpoints_resnet18[\"rand-sigma\"] = {\n",
    "#     3: Path(\"/hkfs/work/workspace/scratch/qv2382-madonna-ddp/madonna/models/fed-randsigma/0/weights3\"),\n",
    "#     0: Path(\"/hkfs/work/workspace/scratch/qv2382-madonna-ddp/madonna/models/fed-randsigma/1/weights0\"),\n",
    "#     2: Path(\"/hkfs/work/workspace/scratch/qv2382-madonna-ddp/madonna/models/fed-randsigma/2/weights2\"),\n",
    "#     1: Path(\"/hkfs/work/workspace/scratch/qv2382-madonna-ddp/madonna/models/fed-randsigma/3/weights1\"),\n",
    "# }\n",
    "checkpoints[\"resnet\"] = {\n",
    "\t0: Path(\"/hkfs/work/workspace/scratch/qv2382-madonna2/madonna/models/baseline/9/weights/\"),\n",
    "\t1: Path(\"/hkfs/work/workspace/scratch/qv2382-madonna2/madonna/models/baseline/23/weights/\"),\n",
    "\t2: Path(\"/hkfs/work/workspace/scratch/qv2382-madonna2/madonna/models/baseline/24/weights/\"),\n",
    "}\n",
    "\t\n",
    "checkpoints[\"vit\"] = {\n",
    "\t0: Path(\"/hkfs/work/workspace/scratch/qv2382-madonna2/madonna/models/baseline/28/weights/\"),\n",
    "\t1: Path(\"/hkfs/work/workspace/scratch/qv2382-madonna2/madonna/models/baseline/29/weights/\"),\n",
    "\t2: Path(\"/hkfs/work/workspace/scratch/qv2382-madonna2/madonna/models/baseline/31/weights/\"),\n",
    "}\n",
    "\n",
    "# combos = [[0, 1], [0, 2], [0, 3], [1, 2], [1, 3], [2, 3]]\n",
    "# epochs = [\"000\", \"024\", \"049\", \"074\", \"099\", \"124\", \"149\", \"174\", \"199\", \"224\", \"249\", \"274\", \"299\", ]  # \n",
    "epochs = [\n",
    "    \"epoch_000.pt\", \n",
    "    'epoch_004.pt',  \n",
    "    \"epoch_009.pt\", \n",
    "    'epoch_014.pt',  \n",
    "    \"epoch_019.pt\", \n",
    "    'epoch_024.pt',\n",
    "    'epoch_029.pt', \n",
    "    'epoch_034.pt',\n",
    "    'epoch_039.pt',  \n",
    "    'epoch_044.pt',\n",
    "    'epoch_049.pt',  \n",
    "    'epoch_054.pt',\n",
    "    'epoch_059.pt',  \n",
    "    'epoch_064.pt',\n",
    "    'epoch_069.pt',  \n",
    "    'epoch_074.pt',\n",
    "    'epoch_079.pt',  \n",
    "    'epoch_084.pt',\n",
    "    'epoch_089.pt',  \n",
    "    'epoch_094.pt',\n",
    "    'epoch_099.pt',  \n",
    "    'epoch_104.pt',\n",
    "    'epoch_109.pt',  \n",
    "    'epoch_114.pt',\n",
    "    'epoch_119.pt',\n",
    "    'epoch_124.pt',\n",
    "]\n",
    "\n",
    "# svd_model_dict = torch.load(oialr_checkpoint_folder, map_location=\"cpu\")\n",
    "# baseline_model_dict = torch.load(baseline_checkpoint_folder, map_location=\"cpu\")\n",
    "# print(list(baseline_model_dict[\"model\"].keys()))\n",
    "\n",
    "# x = torch.rand(10)\n",
    "# print(x.nbytes)\n",
    "# get 2D reps for a checkpoint (fn)\n",
    "\n",
    "def get_2d_reps(model_dict, use_qr, float64=False):\n",
    "    ret_dict = {}\n",
    "    # nbytes = 0\n",
    "    for n in model_dict['model']:\n",
    "        p = model_dict['model'][n]\n",
    "        # print(n, p.shape, p.nbytes)\n",
    "        if p.ndim < 2:\n",
    "            continue\n",
    "\n",
    "        hld = p\n",
    "        if p.ndim > 2:  # collapse down to 2D\n",
    "            shp = p.shape\n",
    "            hld = p.view(p.shape[0], -1)\n",
    "        # print(hld.shape)\n",
    "        trans = hld.shape[0] < hld.shape[1]\n",
    "        if trans:  # make 2D rep TS\n",
    "            hld = hld.T\n",
    "\n",
    "        if float64:\n",
    "            hld = hld.to(torch.float64)\n",
    "        if not use_qr:\n",
    "            u, s, vh = torch.linalg.svd(hld, full_matrices=False)\n",
    "            ret_dict[n] = {'u': u, 's': s, 'vh': vh, 'trans': trans, \"w\": hld}\n",
    "        else:\n",
    "            q, r = torch.linalg.qr(hld, mode=\"complete\")\n",
    "            ret_dict[n] = {'q': q, \"r\": r, 'trans': trans, \"w\": hld}\n",
    "        \n",
    "        # nbytes += u.nbytes\n",
    "        # nbytes += s.nbytes\n",
    "        # nbytes += vh.nbytes\n",
    "    # print(nbytes)\n",
    "    return ret_dict\n",
    "\n",
    "def get_2d_reps_from_names(model_dict, base_names, append_names, use_qr, float64=False):\n",
    "    ret_dict = {}\n",
    "    # nbytes = 0\n",
    "    for base in base_names:\n",
    "        p = model_dict['model'][base]\n",
    "        # print(base, p.shape, p.nbytes)\n",
    "        if p.ndim < 2:\n",
    "            continue\n",
    "\n",
    "        hld = p\n",
    "        if p.ndim > 2:  # collapse down to 2D\n",
    "            shp = p.shape\n",
    "            hld = p.view(p.shape[0], -1)\n",
    "        trans = hld.shape[0] < hld.shape[1]\n",
    "        if trans:  # make 2D rep TS\n",
    "            hld = hld.T\n",
    "\n",
    "        for app in append_names[base]:\n",
    "            app_p = model_dict['model'][app]\n",
    "            # print(base, app, app_p.shape)\n",
    "            same_dim = torch.nonzero(torch.tensor(hld.shape) == torch.tensor(app_p.shape)).flatten()[0].item()\n",
    "            # since its the same dim, need to cat it on the OTHER dim...\n",
    "            same_dim = (same_dim + 1) % 2\n",
    "            # print(base, app, hld.shape, app_p.shape)\n",
    "            hld = torch.cat([hld, app_p.unsqueeze(same_dim)], dim=same_dim)\n",
    "\n",
    "        if float64:\n",
    "            hld = hld.to(torch.float64)\n",
    "\n",
    "        # print(base, hld.shape)\n",
    "        if not use_qr:\n",
    "            u, s, vh = torch.linalg.svd(hld, full_matrices=False)\n",
    "            ret_dict[base] = {'u': u, 's': s, 'vh': vh, 'trans': trans, \"w\": hld}\n",
    "        else:\n",
    "            q, r = torch.linalg.qr(hld, mode=\"reduced\")\n",
    "            ret_dict[base] = {'q': q, \"r\": r, 'trans': trans, \"w\": hld}\n",
    "    #     nbytes += u.nbytes\n",
    "    #     nbytes += s.nbytes\n",
    "    #     nbytes += vh.nbytes\n",
    "    # # print(nbytes)\n",
    "    return ret_dict\n",
    "\n",
    "def get_1d_associated_weights(model_dict):\n",
    "    wgts_to_join = {}\n",
    "    nbytes = 0\n",
    "    last_miltidim_w = None\n",
    "    ignore_list = [\"pos_embed\", \"cls_token\"]\n",
    "    for n in model_dict[\"model\"]:\n",
    "        p = model_dict[\"model\"][n]\n",
    "        # print(n, p.shape, p.nbytes)\n",
    "        if n in ignore_list:\n",
    "            continue\n",
    "        if p.ndim > 1:  # and last_miltidim_w is None:\n",
    "            # print(f'mutli dim, start: {n} shape: {p.shape}')\n",
    "            last_miltidim_w = n\n",
    "            if n in wgts_to_join:\n",
    "                raise ValueError\n",
    "            wgts_to_join[n] = []\n",
    "        elif last_miltidim_w is not None and p.ndim == 1:\n",
    "            wgts_to_join[last_miltidim_w].append(n)\n",
    "            # print(f\"to join with {last_miltidim_w}: {n}\")\n",
    "\n",
    "        # print(n, p.shape)\n",
    "    return wgts_to_join\n",
    "\n",
    "class ModelRepsGen(object):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    @staticmethod\n",
    "    def get_model_reps_gen(cat_1d: bool = False, use_qr: bool = False):\n",
    "        for ranks in combos:  # combos are 2d tuples with rankA, rankB\n",
    "            # getting results\n",
    "            # print(f\"working on combo: {ranks}\")\n",
    "            for epoch in epochs:  # load models for each epoch\n",
    "                if not load_models:\n",
    "                    model_a = torch.load(checkpoints[\"ortho-sigma\"][ranks[0]] / f\"epoch_{epoch}.pt\", map_location=map_location)\n",
    "                    model_b = torch.load(checkpoints[\"ortho-sigma\"][ranks[1]] / f\"epoch_{epoch}.pt\", map_location=map_location)\n",
    "                else:\n",
    "                    model_a = models[ranks[0]][epoch]\n",
    "                    model_b = models[ranks[1]][epoch]\n",
    "                # get append lists:\n",
    "                if cat_1d:\n",
    "                    names = get_1d_associated_weights(model_a)\n",
    "                    rep_dict_a = get_2d_reps_from_names(model_dict=model_a, base_names=names.keys(), append_names=names, use_qr=use_qr)\n",
    "                    rep_dict_b = get_2d_reps_from_names(model_dict=model_b, base_names=names.keys(), append_names=names, use_qr=use_qr)\n",
    "                else:\n",
    "                    rep_dict_a = get_2d_reps(model_dict=model_a, use_qr=use_qr)\n",
    "                    rep_dict_b = get_2d_reps(model_dict=model_b, use_qr=use_qr)\n",
    "                yield (ranks, epoch, rep_dict_a, rep_dict_b)\n",
    "\n",
    "    def __len__():\n",
    "        return len(combos) + len(epochs)\n",
    "    \n",
    "gen_itter = ModelRepsGen()\n",
    "# sim = cossim(buff[i], buff[j])\n",
    "# map_location = \"cpu\"  #\"gpu:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "# chkpt = torch.load(checkpoints_resnet18[\"ortho-sigma\"][0] / \"epoch_299.pt\", map_location=map_location)\n",
    "# for n in chkpt[\"model\"]:\n",
    "#     p = chkpt[\"model\"][n]\n",
    "#     print(n, p.shape)\n",
    "# _ = get_2d_reps(checkpoints[\"ortho-sigma\"][0] / \"epoch_299.pt\")\n",
    "# test = get_1d_associated_weights(model_dict=chkpt)\n",
    "# reps_2d_app = get_2d_reps_from_names(model_dict=chkpt, base_names=test.keys(), append_names=test, filepath=checkpoints[\"ortho-sigma\"][0] / \"epoch_299.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_models = False\n",
    "models = {}\n",
    "map_location = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "if load_models:\n",
    "    for rank in range(4):\n",
    "        models[rank] = {}\n",
    "        for epoch in epochs:\n",
    "            models[rank][epoch] = torch.load(checkpoints_resnet18[\"ortho-sigma\"][rank] / f\"epoch_{epoch}.pt\", map_location=map_location)\n",
    "            # models[rank][epoch] = torch.load(checkpoints[\"ortho-sigma\"][rank] / f\"epoch_{epoch}.pt\", map_location=map_location)\n",
    "        print(f\"loaded models for rank: {rank}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original compare with 5 epochs previous\n",
    "run_cell = False\n",
    "if run_cell:\n",
    "    avg_sim = {}\n",
    "    avg_offdiag_sim = {}\n",
    "    avg_norm = {}\n",
    "    # load 1st model and get uvts\n",
    "    model = torch.load(checkpoints[\"vit\"][2] / f\"{epochs[0]}\", map_location=map_location)\n",
    "    last_uvts = get_2d_reps(model, use_qr=False)\n",
    "    # loop through next models\n",
    "    epoch = 5\n",
    "    for comp in epochs[1:]:\n",
    "        print(f\"comp_model: {checkpoints['vit'][2] / comp}\")\n",
    "        comp_model = torch.load(checkpoints[\"vit\"][2] / comp, map_location=map_location)\n",
    "        comp_uvts = get_2d_reps(comp_model, use_qr=False)\n",
    "        avg_sim[epoch] = {}\n",
    "        avg_offdiag_sim[epoch] = {}\n",
    "        avg_norm[epoch] = {}\n",
    "        for n in comp_uvts:\n",
    "            uvh_p = last_uvts[n]['u'] @ last_uvts[n][\"vh\"]\n",
    "            uvh_c = comp_uvts[n]['u'] @ comp_uvts[n][\"vh\"]\n",
    "            sim = (uvh_p.T @ uvh_c) / (torch.max(torch.norm(uvh_p, dim=0)) * torch.max(torch.norm(uvh_c, dim=0)))\n",
    "            avg_sim[epoch][n] = sim.diag().mean().item()\n",
    "            sim = sim.fill_diagonal_(0)\n",
    "            avg_offdiag_sim[epoch][n] = sim.sum().item()\n",
    "            uvh_p = uvh_p.to(\"cpu\")\n",
    "            uvh_c = uvh_c.to(\"cpu\")\n",
    "            # norm = torch.linalg.norm(uvh_p @ uvh_p.T - uvh_c @ uvh_c.T)\n",
    "            # avg_norm[epoch][n] = norm.item()\n",
    "\n",
    "        last_uvts = comp_uvts\n",
    "        epoch += 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_cell = False  # QR comparison\n",
    "\n",
    "model_to_check = \"vit\"\n",
    "\n",
    "if run_cell:\n",
    "    use_qr = True\n",
    "    # Original compare with 5 epochs previous\n",
    "    avg_sim = {}\n",
    "    avg_offdiag_sim = {}\n",
    "    avg_norm = {}\n",
    "    r_dist = {}\n",
    "    # load 1st model and get uvts\n",
    "    model = torch.load(checkpoints[model_to_check][2] / f\"{epochs[0]}\", map_location=map_location)\n",
    "    last_uvts = get_2d_reps(model, use_qr=use_qr)\n",
    "    # loop through next models\n",
    "    epoch = 5\n",
    "    for comp in epochs[1:]:\n",
    "        print(f\"comp_model: {checkpoints[model_to_check][2] / comp}\")\n",
    "        comp_model = torch.load(checkpoints[model_to_check][2] / comp, map_location=map_location)\n",
    "        comp_uvts = get_2d_reps(comp_model, use_qr=use_qr)\n",
    "        avg_sim[epoch] = {}\n",
    "        avg_offdiag_sim[epoch] = {}\n",
    "        avg_norm[epoch] = {}\n",
    "        r_dist[epoch] = {}\n",
    "        for n in comp_uvts:\n",
    "            q_p = last_uvts[n]['q']\n",
    "            q_c = comp_uvts[n]['q']\n",
    "            sim = (q_p.T @ q_c) / (torch.max(torch.norm(q_p, dim=0)) * torch.max(torch.norm(q_c, dim=0)))\n",
    "            avg_sim[epoch][n] = sim.diag().mean().item()\n",
    "            sim = sim.fill_diagonal_(0)\n",
    "            avg_offdiag_sim[epoch][n] = sim.sum().item()\n",
    "\n",
    "            rp = last_uvts[n]['r']\n",
    "            rc = comp_uvts[n]['r']\n",
    "            \n",
    "            r_distn = torch.sqrt((rp - rc).pow(2).sum()).item()\n",
    "            r_dist[epoch][n] = r_distn\n",
    "\n",
    "        #     print(r_dist)\n",
    "        #     break\n",
    "        # break\n",
    "            # uvh_p = uvh_p.to(\"cpu\")\n",
    "            # uvh_c = uvh_c.to(\"cpu\")\n",
    "            # norm = torch.linalg.norm(uvh_p @ uvh_p.T - uvh_c @ uvh_c.T)\n",
    "            # avg_norm[epoch][n] = norm.item()\n",
    "\n",
    "\n",
    "        last_uvts = comp_uvts\n",
    "        epoch += 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# load R/Sim mats from csv\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "model_target = \"resnet\"\n",
    "heatmap_min = 0.8\n",
    "line_min = 0.75\n",
    "\n",
    "r_dist_df = pd.read_csv(f\"{model_target}/qr/rdist.csv\")\n",
    "# r_sim_df = pd.read_csv(f\"{model_target}/qr/rsim.csv\")\n",
    "sim_dist_df = pd.read_csv(f\"{model_target}/qr/sim.csv\")\n",
    "\n",
    "r_dist_df = r_dist_df.set_index(\"Unnamed: 0\")\n",
    "# r_sim_df = r_sim_df.set_index(\"Unnamed: 0\")\n",
    "sim_dist_df = sim_dist_df.set_index(\"Unnamed: 0\")\n",
    "print(r_dist_df.index[:3])\n",
    "# print()\n",
    "# r_dist_df = 1 - r_dist_df.iloc[:, :-5] / r_dist_df.to_numpy().max()\n",
    "r_dist_df = r_dist_df.iloc[:, :-5]\n",
    "\n",
    "means = r_dist_df.iloc[3:].mean(0).values\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "# from matplotlib import rc\n",
    "new_rc = {\n",
    "    # \"figure.figsize\": figSize,\n",
    "    \"figure.autolayout\": True,\n",
    "    \"text.usetex\": True,\n",
    "    \"axes.labelsize\": 10,\n",
    "    \"font.size\": 8,\n",
    "    \"legend.fontsize\": 8,\n",
    "    \"xtick.labelsize\": 8,\n",
    "    \"ytick.labelsize\": 8 ,\n",
    "    'font.family': 'serif',\n",
    "    'font.serif': [\"Palatino\"],\n",
    "}\n",
    "# rc(**new_rc)\n",
    "plt.rcParams.update(new_rc)\n",
    "\n",
    "# avg_sim_db = pd.DataFrame.from_dict(avg_sim)\n",
    "\n",
    "# print(avg_sim_db)\n",
    "fig, ((ax_heatmap, ax_colorbar), (ax_line, ax4)) = plt.subplots(\n",
    "    2, 2, sharex=\"col\",\n",
    "    figsize=(10, 7),\n",
    "    gridspec_kw={'height_ratios': [4, 1], \"width_ratios\": [15, 1], \"hspace\": 0.01, \"wspace\": 0.01}\n",
    ")\n",
    "\n",
    "sns.heatmap(r_dist_df, ax=ax_heatmap, cbar_ax=ax_colorbar, vmin=heatmap_min, vmax=1.0)\n",
    "x = [c + 0.5 for c in range(len(means))]\n",
    "sns.lineplot(x=x, y=means, color='black', ax=ax_line)\n",
    "ax_line.set_ylim([line_min, 1.])\n",
    "ax_line.set_yticks([0.8, 1.0])\n",
    "ax_line.set_xlabel(\"Epoch\", fontsize=20)\n",
    "ax_line.tick_params(labelsize=14)\n",
    "\n",
    "offset = 10 if model_target == \"vit\" else 40\n",
    "ax_heatmap.set_yticks([offset, r_dist_df.shape[0] - offset])  # Ticks at the beginning and end\n",
    "ax_heatmap.set_yticklabels(['Last Layers', 'First Layers'], rotation=90, fontsize=14)\n",
    "ax_heatmap.tick_params(length=0)\n",
    "ax_heatmap.set_ylabel(\"Network layer\", fontsize=20)\n",
    "\n",
    "ax_colorbar.set_ylabel(\"Similarity\", fontsize=14, labelpad=6)\n",
    "ax_colorbar.set_yticks([0.80, 0.85, 0.9, 0.95, 1.0])\n",
    "ax_colorbar.set_yticklabels([f\"{x:.2f}\" for x in ax_colorbar.get_yticks()], size=14)\n",
    "\n",
    "# ax_line.set_xticks(ax_heatmap.get_xticks())\n",
    "# ax_line.set_xticklabels(ax_heatmap.get_xticks(), size=14)\n",
    "\n",
    "ax_line.set_ylabel(\"Mean\\nSimilarity\", fontsize=14)\n",
    "ax4.axis('off')\n",
    "\n",
    "# Optional: Adjust layout\n",
    "plt.tight_layout()\n",
    "fig.savefig(f\"/hkfs/work/workspace/scratch/qv2382-madonna-ddp/madonna/analysis/figures/{model_target}-r-cdist.pdf\", dpi=1000)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "# from matplotlib import rc\n",
    "new_rc = {\n",
    "    # \"figure.figsize\": figSize,\n",
    "    \"figure.autolayout\": True,\n",
    "    \"text.usetex\": True,\n",
    "    \"axes.labelsize\": 10,\n",
    "    \"font.size\": 8,\n",
    "    \"legend.fontsize\": 8,\n",
    "    \"xtick.labelsize\": 8,\n",
    "    \"ytick.labelsize\": 8 ,\n",
    "    'font.family': 'serif',\n",
    "    'font.serif': [\"Palatino\"],\n",
    "}\n",
    "# rc(**new_rc)\n",
    "plt.rcParams.update(new_rc)\n",
    "\n",
    "avg_sim_db = pd.DataFrame.from_dict(avg_sim)\n",
    "\n",
    "# print(avg_sim_db)\n",
    "fig, ((ax_heatmap, ax_colorbar), (ax_line, ax4)) = plt.subplots(\n",
    "    2, 2, sharex=\"col\",\n",
    "    figsize=(8, 5),\n",
    "    gridspec_kw={'height_ratios': [4, 1], \"width_ratios\": [15, 1], \"hspace\": 0}\n",
    ")\n",
    "\n",
    "sns.heatmap(avg_sim_db, vmin=0.75, vmax=1.0, ax=ax_heatmap, cbar_ax=ax_colorbar)\n",
    "means = avg_sim_db.mean(0).values\n",
    "x = [c + 0.5 for c in range(len(means))]\n",
    "sns.lineplot(x=x, y=means, color='black', ax=ax_line)\n",
    "\n",
    "# ax_line.set(ylim=(0.78, 1.0))\n",
    "\n",
    "ax_heatmap.set_yticks([10, avg_sim_db.shape[0] - 10])  # Ticks at the beginning and end\n",
    "ax_heatmap.set_yticklabels(['Last Layers', 'First Layers'], rotation=90, fontsize=14)\n",
    "ax_heatmap.tick_params(length=0)\n",
    "ax_heatmap.set_ylabel(\"Network layer\", fontsize=20)\n",
    "\n",
    "ax_colorbar.set_ylabel(\"Stability\", fontsize=20)\n",
    "# ax_colorbar.set_yticks([0.8, 0.85, 0.9, 0.95, 1.0])\n",
    "ax_colorbar.set_yticklabels([f\"{x:.2f}\" for x in ax_colorbar.get_yticks()], size=14)\n",
    "\n",
    "# ax_line.set_xticks(ax_heatmap.get_xticks())\n",
    "# ax_line.set_xticklabels(ax_heatmap.get_xticks(), size=14)\n",
    "\n",
    "ax_line.set_ylabel(\"Mean\\nStability\", fontsize=16)\n",
    "ax4.axis('off')\n",
    "\n",
    "# Optional: Adjust layout\n",
    "plt.tight_layout()\n",
    "fig.savefig(\"/hkfs/work/workspace/scratch/qv2382-madonna-ddp/madonna/analysis/figures/vit_sim_plot.pdf\", dpi=1000)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_offsim_db = pd.DataFrame.from_dict(avg_offdiag_sim)\n",
    "print(avg_offsim_db.shape)\n",
    "sns.heatmap(avg_offdiag_sim)#, vmin=0.8, vmax=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_db = pd.DataFrame.from_dict(avg_norm)\n",
    "# print(norm_db)\n",
    "# sns.heatmap(norm_db)#, vmin=0.8, vmax=1.0)\n",
    "\n",
    "fig, ((ax_heatmap, ax_colorbar), (ax_line, ax4)) = plt.subplots(\n",
    "    2, 2, sharex=\"col\",\n",
    "    figsize=(8, 5),\n",
    "    gridspec_kw={'height_ratios': [4, 1], \"width_ratios\": [15, 1], \"hspace\": 0}\n",
    ")\n",
    "\n",
    "sns.heatmap(norm_db, ax=ax_heatmap, cbar_ax=ax_colorbar)\n",
    "means = norm_db.mean(0).values\n",
    "x = [c + 0.5 for c in range(len(means))]\n",
    "sns.lineplot(x=x, y=means, color='black', ax=ax_line)\n",
    "# ax_line.set(ylim=(0.78, 1.0))\n",
    "\n",
    "ax_heatmap.set_yticks([10, norm_db.shape[0] - 10])  # Ticks at the beginning and end\n",
    "ax_heatmap.set_yticklabels(['Last Layers', 'First Layers'], rotation=90, fontsize=12)\n",
    "ax_heatmap.tick_params(length=0)\n",
    "ax_heatmap.set_ylabel(\"Network layer\", fontsize=18)\n",
    "\n",
    "ax_colorbar.set_ylabel(\"Rotationally Invarient Metric\", fontsize=18)\n",
    "# ax_colorbar.set_yticks([0.8, 0.85, 0.9, 0.95, 1.0])\n",
    "ax_colorbar.set_yticklabels([int(i) for i in ax_colorbar.get_yticks()], size=12)\n",
    "\n",
    "ax_line.set_ylabel(\"Mean\\nMetric\", fontsize=16)\n",
    "# ax_line.set_xticklabels(ax_line.get_xticks(), size=8)\n",
    "ax4.axis('off')\n",
    "\n",
    "# Optional: Adjust layout\n",
    "plt.tight_layout()\n",
    "fig.savefig(\"/hkfs/work/workspace/scratch/qv2382-madonna-ddp/madonna/analysis/figures/vit_norm_plot.pdf\", dpi=1000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Goal here: compare basic 2D reps with each other (not including 1D appends)\n",
    "\n",
    "# 1. load models for each epoch\n",
    "# 2. get 2d reps\n",
    "# 3. compare 2d reps (cossim) + record the averages (dict, layernames == keys)\n",
    "# 4. make heatmap\n",
    "\n",
    "avg_similarity = {}  # epoch: layer: \n",
    "for ranks, epoch, rep_dict_a, rep_dict_b in track(gen_itter.get_model_reps_gen(False, use_qr=False), description=\"Processing 2D w/o 1D layers\",):\n",
    "    # rep_dicts are [name] = {u, s, vh}\n",
    "    if epoch not in avg_similarity:\n",
    "        avg_similarity[epoch] = {}\n",
    "    cc = 0\n",
    "    for layer in rep_dict_a:  # keys are the same\n",
    "        layer_a = rep_dict_a[layer]\n",
    "        layer_b = rep_dict_b[layer]\n",
    "        \n",
    "        uvh_a = layer_a['u'] @ layer_a['vh']\n",
    "        uvh_b = layer_b['u'] @ layer_b['vh']\n",
    "        sim = (uvh_a.T @ uvh_b) / (torch.max(torch.norm(uvh_a, dim=0)) * torch.max(torch.norm(uvh_b, dim=0)))\n",
    "        # qa = layer_a[\"q\"]\n",
    "        # qb = layer_b[\"q\"]\n",
    "        # sim = (qa.T @ qb) / (torch.max(torch.norm(qa, dim=0)) * torch.max(torch.norm(qb, dim=0)))\n",
    "        sim = sim.diag()  # should be AtA because uvh is column vectors\n",
    "        \n",
    "        # print(layer, ranks, epoch, sim.mean())\n",
    "\n",
    "        if layer in avg_similarity[epoch]:\n",
    "            avg_similarity[epoch][layer] += sim.mean().item() / len(combos)\n",
    "        else:  # NOTE: div by len(combos to get the average at the)\n",
    "            avg_similarity[epoch][layer] = sim.mean().item() / len(combos)\n",
    "    # print(uvh_a.T @ uvh_b)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting heatmap from last step\n",
    "import seaborn as sns\n",
    "\n",
    "avg_sim = pd.DataFrame.from_dict(avg_similarity)\n",
    "print(avg_sim)\n",
    "\n",
    "sns.heatmap(avg_sim)#, vmin=0.8, vmax=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Goal here: compare 2D reps with each other (INCLUDING 1D appends)\n",
    "\n",
    "# 1. load models\n",
    "# 2. get append lists\n",
    "# 3. get 2d reps\n",
    "# 4. compare 2d reps (cossim) + record the averages (dict, layernames == keys)\n",
    "# 5. make heatmap\n",
    "avg_similarity_w1d = {}  # epoch: layer: \n",
    "c = 0\n",
    "for ranks, epoch, rep_dict_a, rep_dict_b in track(gen_itter.get_model_reps_gen(True), description=\"Processing 2D with 1D layers\",):\n",
    "    if epoch not in avg_similarity_w1d:\n",
    "        avg_similarity_w1d[epoch] = {}\n",
    "    for layer in rep_dict_a:  # keys are the same\n",
    "        layer_a = rep_dict_a[layer]\n",
    "        layer_b = rep_dict_b[layer]\n",
    "        uvh_a = layer_a['u'] @ layer_a['vh']\n",
    "        uvh_b = layer_b['u'] @ layer_b['vh']\n",
    "        sim = (uvh_a.T @ uvh_b) / (torch.max(torch.norm(uvh_a, dim=0)) * torch.max(torch.norm(uvh_b, dim=0)))\n",
    "        sim = sim.diag()  # should be AtA because uvh is column vectors\n",
    "        # print(layer, ranks, epoch, sim.mean())\n",
    "\n",
    "        if layer in avg_similarity_w1d[epoch]:\n",
    "            avg_similarity_w1d[epoch][layer] += sim.mean().item() / len(combos)\n",
    "        else:  # NOTE: div by len(combos to get the average at the)\n",
    "            avg_similarity_w1d[epoch][layer] = sim.mean().item() / len(combos)\n",
    "    #     c += 1\n",
    "    #     if c > 2:   \n",
    "    #         break\n",
    "    # break\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# plotting heatmap from last step\n",
    "\n",
    "avg_sim_w1d = pd.DataFrame.from_dict(avg_similarity_w1d)\n",
    "\n",
    "# avg_sim_w1d /= 6\n",
    "\n",
    "sns.heatmap(avg_sim_w1d, vmin=0.8, vmax=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Goal here: when 2D reps differ, do the sum of the matmul for that row == 1\n",
    "avg_uvh_sums = {}  # epoch: layer: \n",
    "for ranks, epoch, rep_dict_a, rep_dict_b in gen_itter.get_model_reps_gen(False):\n",
    "    # track(gen_itter.get_model_reps_gen(False), description=\"Processing 2D w/o 1D layers\",):\n",
    "    # print(ranks, epoch)\n",
    "        # rep_dicts are [name] = {u, s, vh}\n",
    "    if epoch not in avg_uvh_sums:\n",
    "        avg_uvh_sums[epoch] = {}\n",
    "    for layer in rep_dict_a:  # keys are the same\n",
    "        layer_a = rep_dict_a[layer]\n",
    "        layer_b = rep_dict_b[layer]\n",
    "        uvh_a = layer_a['u'] @ layer_a['vh']\n",
    "        uvh_b = layer_b['u'] @ layer_b['vh']\n",
    "        sim = (uvh_a.T @ uvh_b) / (torch.max(torch.norm(uvh_a, dim=0)) * torch.max(torch.norm(uvh_b, dim=0)))\n",
    "        # sim = sim.diag()  # should be AtA because uvh is column vectors\n",
    "        # if epoch == \"024\":\n",
    "        # sim[sim.abs() < sim[0, 0] * 0.001] = 0\n",
    "        \n",
    "        # print(sim[:5, :5], sim.abs().sum(1))\n",
    "        # break\n",
    "        \n",
    "        if layer in avg_uvh_sums[epoch]:\n",
    "            avg_uvh_sums[epoch][layer] += sim.sum().item() / sim.shape[0] / len(combos)\n",
    "        else:  # NOTE: div by len(combos to get the average at the)\n",
    "            avg_uvh_sums[epoch][layer] = sim.sum().item() / sim.shape[0] / len(combos)\n",
    "\n",
    "    # layer = 'layer3.0.conv2.weight'\n",
    "    # layer_a = rep_dict_a[layer]\n",
    "    # layer_b = rep_dict_b[layer]\n",
    "    # uvh_a = layer_a['u'] @ layer_a['vh']\n",
    "    # uvh_b = layer_b['u'] @ layer_b['vh']\n",
    "    # sim = (uvh_a.T @ uvh_b) / (torch.max(torch.norm(uvh_a, dim=0)) * torch.max(torch.norm(uvh_b, dim=0)))\n",
    "    # # sim = sim.diag()  # should be AtA because uvh is column vectors\n",
    "    # # if epoch == \"024\":\n",
    "    # # sim[sim.abs() < sim[0, 0] * 0.001] = 0\n",
    "    \n",
    "    # print(sim[:, 0].sum().item(), sim.sum().item(), uvh_a.shape)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_sum = pd.DataFrame.from_dict(avg_uvh_sums)\n",
    "\n",
    "# avg_sum_w1d /= 6\n",
    "print(avg_sum)\n",
    "\n",
    "sns.heatmap(avg_sum, vmin=0.8, vmax=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# NOTE: this is with the 1d vecs folder in\n",
    "\n",
    "# Goal here: when 2D reps differ, do the sum of the matmul for that row == 1\n",
    "avg_uvh_sums_w1d = {}  # epoch: layer: \n",
    "c = 0\n",
    "model_app_list = None\n",
    "for ranks, epoch, rep_dict_a, rep_dict_b in track(gen_itter.get_model_reps_gen(cat_1d=True), description=\"Processing 2D with 1D layers\",):\n",
    "    if epoch not in avg_uvh_sums_w1d:\n",
    "        avg_uvh_sums_w1d[epoch] = {}\n",
    "    for layer in rep_dict_a:  # keys are the same\n",
    "        layer_a = rep_dict_a[layer]\n",
    "        layer_b = rep_dict_b[layer]\n",
    "        uvh_a = layer_a['u'] @ layer_a['vh']\n",
    "        uvh_b = layer_b['u'] @ layer_b['vh']\n",
    "        sim = (uvh_a.T @ uvh_b) / (torch.max(torch.norm(uvh_a, dim=0)) * torch.max(torch.norm(uvh_b, dim=0)))\n",
    "        # sim = sim.diag()  # should be AtA because uvh is column vectors\n",
    "        \n",
    "        if layer in avg_uvh_sums_w1d[epoch]:\n",
    "            avg_uvh_sums_w1d[epoch][layer] += sim.abs().sum(1).mean().item() / len(combos)\n",
    "        else:  # NOTE: div by len(combos to get the average at the)\n",
    "            avg_uvh_sums_w1d[epoch][layer] = sim.abs().sum(1).mean().item() / len(combos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "avg_sum_w1d = pd.DataFrame.from_dict(avg_uvh_sums_w1d)\n",
    "\n",
    "# avg_sum_w1d /= 6\n",
    "print(avg_sum_w1d)\n",
    "\n",
    "sns.heatmap(avg_sum_w1d, vmin=0.8, vmax=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing for new ideas here:\n",
    "\n",
    "# current idea: concat [u1, u2] and [v1, v2] to make a wider effect area, then take svd and compare us with each other\n",
    "\n",
    "# for ranks in combos:  # combos are 2d tuples with rankA, rankB\n",
    "#     # getting results\n",
    "#     # print(f\"working on combo: {ranks}\")\n",
    "#     for epoch in epochs:  # load models for each epoch\n",
    "ranks = combos[0]\n",
    "model_a = models[0][epochs[-1]]\n",
    "# print(ranks)\n",
    "model_b = models[1][epochs[-1]]\n",
    "\n",
    "rep_dict_a = get_2d_reps(model_dict=model_a, use_qr=False, float64=True)\n",
    "rep_dict_b = get_2d_reps(model_dict=model_b, use_qr=False, float64=True)\n",
    "\n",
    "u1 = rep_dict_a['layer1.1.conv1.weight'][\"u\"]\n",
    "u2 = rep_dict_b['layer1.1.conv1.weight'][\"u\"]\n",
    "s1 = rep_dict_a['layer1.1.conv1.weight'][\"s\"]\n",
    "s2 = rep_dict_b['layer1.1.conv1.weight'][\"s\"]\n",
    "vh1 = rep_dict_a['layer1.1.conv1.weight'][\"vh\"]\n",
    "vh2 = rep_dict_b['layer1.1.conv1.weight'][\"vh\"]\n",
    "# u1 = rep_dict_a['conv1.weight'][\"u\"]\n",
    "# u2 = rep_dict_b['conv1.weight'][\"u\"]\n",
    "# s1 = rep_dict_a['conv1.weight'][\"s\"]\n",
    "# s2 = rep_dict_b['conv1.weight'][\"s\"]\n",
    "# vh1 = rep_dict_a['conv1.weight'][\"vh\"]\n",
    "# vh2 = rep_dict_b['conv1.weight'][\"vh\"]\n",
    "s_mean = (s1 + s2) / 2.\n",
    "\n",
    "w1 = u1 @ torch.diag(s1) @ vh1\n",
    "w2 = u2 @ torch.diag(s2) @ vh2\n",
    "\n",
    "# print((u1.T @ u2).diag())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u1f, s1f, vh1f = torch.linalg.svd(w1, full_matrices=True)\n",
    "u2f, s2f, vh2f = torch.linalg.svd(w2, full_matrices=True)\n",
    "\n",
    "q1r, r1r = torch.linalg.qr(w1, mode=\"reduced\")\n",
    "q2r, r2r = torch.linalg.qr(w2, mode=\"reduced\")\n",
    "\n",
    "q1f, r1f = torch.linalg.qr(w1, mode=\"complete\")\n",
    "q2f, r2f = torch.linalg.qr(w2, mode=\"complete\")\n",
    "\n",
    "print(u1f.shape, s1f.shape, vh1f.shape)\n",
    "print(u1.shape, s1.shape, vh1.shape)\n",
    "\n",
    "# print(u1.T @ u1f[:, :256])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = u1 @ vh1\n",
    "b = u2 @ vh2\n",
    "\n",
    "# a = q1f\n",
    "# b = q2f\n",
    "\n",
    "def get_rotation_btw_bases(basis_a, basis_b, halfway=True, print_angle=False):\n",
    "    # TODO: rename basis_a -> to_rotate and basis_b -> target_basis\n",
    "    # create a rotation to rotate basis_a to basis_b\n",
    "    # returns: R so that R @ A == B\n",
    "\n",
    "    # steps: \n",
    "    #   1. create rotation to rotate A all the way to B\n",
    "    #   2. find angle of rotation\n",
    "    #   3. modify rotation matrix to only rotation halfway between A and B\n",
    "\n",
    "    # step 1: create rotation to rotate A all the way to B\n",
    "    rot = torch.zeros((basis_a.shape[0], basis_a.shape[0]), dtype=basis_a.dtype, device=basis_a.device)\n",
    "    # rot = a @ b.T\n",
    "    for col in range(basis_a.shape[1]):\n",
    "        rot += torch.kron(basis_a[:, col], basis_b[:, col].unsqueeze(1))\n",
    "    #     # rot += basis_a[:, col].unsqueeze(1) @ basis_b[:, col].unsqueeze(0)\n",
    "        \n",
    "    # print(torch.allclose(rot, basis_a @ basis_b.T))\n",
    "    # print()\n",
    "    # if not halfway:\n",
    "    #     return rot\n",
    "    \n",
    "    # step 2: find angle of rotation\n",
    "    \n",
    "    # angle = torch.arccos(0.5 * (torch.trace(rot) - 1))\n",
    "    # print(f\"\\t {torch.trace(rot):.4f} \\t{torch.rad2deg(angle).item():.4f}\\t {(rot.T @ rot).diag().mean():.3f}\")\n",
    "    # print(f\"\\t {torch.linalg.eigvals(rot).real}\")\n",
    "    \n",
    "    # if torch.isnan(angle):\n",
    "    #     raise RuntimeError(\"nan angle\")\n",
    "    \n",
    "    # if print_angle:\n",
    "    #     print(f\"Angle between bases: {torch.rad2deg(angle).item():.4f}\")\n",
    "    if not halfway:\n",
    "        return rot\n",
    "\n",
    "    # step 3. modify rotation matrix to only rotation halfway between A and B\n",
    "    alpha = (2 * torch.cos(angle / 2) + 1) / rot.diag().sum()\n",
    "    new_diag = alpha / rot.shape[0] * rot.diag()\n",
    "    rot = rot.fill_diagonal_(0)\n",
    "    rot += torch.diag(new_diag)\n",
    "\n",
    "    return rot\n",
    "\n",
    "print(\"U\")\n",
    "r = get_rotation_btw_bases(basis_a=u1f, basis_b=u2f, halfway=False, print_angle=True)\n",
    "print(\"Vh\")\n",
    "r = get_rotation_btw_bases(basis_a=vh1f, basis_b=vh2f, halfway=False, print_angle=True)\n",
    "\n",
    "# l = b @ a.T - a @ b.T\n",
    "# r = b @ a.T\n",
    "\n",
    "# print(r)\n",
    "\n",
    "# ub, sb, vhb = torch.linalg.svd(b, full_matrices=False)\n",
    "# b_inv = vhb.T @ (1/sb).diag() @ ub.T\n",
    "# r = a @ b_inv\n",
    "print(torch.allclose(r @ vh1, vh2))\n",
    "# print(torch.linalg.det(u1f), torch.linalg.det(vh1))\n",
    "\n",
    "# print(f\"is R orthogonal?-> {torch.allclose(r.T, torch.linalg.inv(r))}\")\n",
    "# print(f\"det of R: {torch.linalg.det(r)}\")\n",
    "\n",
    "# print(((r @ q1f) - q2f).max())\n",
    "# # print(((r @ a) - b).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rotate all of the bases to rank zero's bases\n",
    "# get_model_reps_with_r0(cat_1d: bool = False, use_qr: bool = False, which_epoch=\"299\"):\n",
    "r0combos = [1, 2, 3]\n",
    "cat_1d = True\n",
    "use_qr = False\n",
    "which_epoch = \"299\"\n",
    "float64 = True\n",
    "\n",
    "del model_0, rep_dict_0, rep_dict_l\n",
    "\n",
    "if not load_models:\n",
    "    model_0 = torch.load(checkpoints[\"ortho-sigma\"][0] / f\"epoch_{which_epoch}.pt\", map_location=map_location)\n",
    "else:\n",
    "    model_0 = models[0][which_epoch]\n",
    "\n",
    "if cat_1d:\n",
    "    names = get_1d_associated_weights(model_a)\n",
    "    rep_dict_0 = get_2d_reps_from_names(model_dict=model_0, base_names=names.keys(), append_names=names, use_qr=use_qr, float64=float64)\n",
    "else:\n",
    "    rep_dict_0 = get_2d_reps(model_dict=model_0, use_qr=use_qr, float64=float64)\n",
    "\n",
    "# get full Us\n",
    "for layer in rep_dict_0:\n",
    "    layer_0 = rep_dict_0[layer]\n",
    "    uf, _, vhf = torch.linalg.svd(layer_0['w'], full_matrices=True)\n",
    "    layer_0[\"uf\"] = uf\n",
    "    layer_0[\"vhf\"] = vhf\n",
    "\n",
    "for partner in r0combos:  # combos are 2d tuples with rankA, rankB\n",
    "    # getting results\n",
    "    if not load_models:\n",
    "        model_l = torch.load(checkpoints[\"ortho-sigma\"][partner] / f\"epoch_{which_epoch}.pt\", map_location=map_location)\n",
    "    else:\n",
    "        model_l = models[partner][which_epoch]\n",
    "    # get append lists:\n",
    "    if cat_1d:\n",
    "        rep_dict_l = get_2d_reps_from_names(model_dict=model_l, base_names=names.keys(), append_names=names, use_qr=use_qr, float64=float64)\n",
    "    else:\n",
    "        rep_dict_l = get_2d_reps(model_dict=model_l, use_qr=use_qr, float64=float64)\n",
    "\n",
    "    # loop through the dict and move the \n",
    "    for layer in rep_dict_l:  # keys are the same\n",
    "        layer_0 = rep_dict_0[layer]\n",
    "        layer_l = rep_dict_l[layer]\n",
    "        ufl, _, vhf = torch.linalg.svd(layer_l['w'], full_matrices=True)\n",
    "\n",
    "        u0 = layer_0['u']\n",
    "        uf0 = layer_0['uf']\n",
    "        ul = layer_l['u']\n",
    "        \n",
    "        v0 = layer_0['vh'].T\n",
    "        vf0 = layer_0['vhf'].T\n",
    "        vl = layer_l['vh'].T\n",
    "        vfl = vhf.T\n",
    "\n",
    "        # print(partner, layer,)\n",
    "        # get number target vectors (shapecount number of vectors with a max of 0\n",
    "        # get number of vectors included in v0 (dont care about full, since there are not sigma values for those)\n",
    "        \n",
    "        # print(f\"U: {(u0.T @ ul).max(dim=0)[0].max():.4f} \\t full: {(uf0.T @ ufl).max(dim=0)[0].max():.4f}\")\n",
    "        ru = get_rotation_btw_bases(basis_a=u0.T, basis_b=ul.T, halfway=False, print_angle=False)\n",
    "\n",
    "        # print(ru)\n",
    "        # break\n",
    "\n",
    "        # print(f\"V: {(v0.T @ vl).max(dim=0)[0].max():.4f} \\t full: {(vf0.T @ vlf).max(dim=0)[0].max():.4f}\")\n",
    "        rv = get_rotation_btw_bases(basis_a=v0.T, basis_b=vl.T, halfway=False, print_angle=False).T\n",
    "        if layer_0['s'].ndim == 1:\n",
    "            layer_0['s'] = layer_0['s'].diag()\n",
    "        layer_0['s'] += ru.T @ layer_l['s'] @ rv  # the same as ru @ ul @ sigmal @ vl.T @ rvt\n",
    "\n",
    "    # break\n",
    "\n",
    "for layer in rep_dict_0:  # finish average of weights\n",
    "    \n",
    "    u0, vh0 = rep_dict_0[layer]['u'], rep_dict_0[layer]['vh']\n",
    "    sig = rep_dict_0[layer]['s'] / len(r0combos) + 1\n",
    "    rep_dict_0[layer]['w'] = u0\n",
    "\n",
    "    \n",
    "# create network\n",
    "# validate on validation set\n",
    "# create network average + validate with that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rep_dict_0 has the dictionary of the 2d representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "wavg = (w1 + w2) / 2\n",
    "ua, sa, vha = torch.linalg.svd(wavg, full_matrices=False)\n",
    "\n",
    "uvh_1 = u1 @ torch.eye(u1.shape[1], dtype=u1.dtype, device=u1.device) @ vh1\n",
    "uvh_2 = u2 @ torch.eye(u1.shape[1], dtype=u1.dtype, device=u1.device) @ vh2\n",
    "\n",
    "uvh_avg = ua @ torch.eye(u1.shape[1], dtype=u1.dtype, device=u1.device) @ vha\n",
    "uvh_avg2 = (uvh_1 + uvh_2) / 2.\n",
    "\n",
    "# print(uvh_1[0])\n",
    "\n",
    "uvh_1n = uvh_1 / torch.norm(uvh_1, dim=0)\n",
    "# print(torch.norm(uvh_1, dim=0))\n",
    "uvh_2n = uvh_2 / torch.norm(uvh_2, dim=0)\n",
    "\n",
    "sim = (uvh_2n.T @ uvh_1n) # / (torch.max(torch.norm(uvh_2, dim=0)) * torch.max(torch.norm(uvh_1, dim=0)))\n",
    "sim2 = (uvh_2.T @ uvh_1) #/ (torch.max(torch.norm(uvh_2, dim=0)) * torch.max(torch.norm(uvh_1, dim=0)))\n",
    "\n",
    "sim_avg = (uvh_2.T @ uvh_avg)\n",
    "sim_avg2 = (uvh_2.T @ uvh_avg2)\n",
    "print(sim_avg.diag()[:8].tolist())\n",
    "print(sim_avg2.diag()[:8].tolist())\n",
    "print(sim2.diag()[:8].tolist())\n",
    "print(1 - ((1 - sim2.diag()[:8]) / 2.))\n",
    "# print(sim2.diag().min(), sim2.diag().max(), sim2.diag().std())\n",
    "\n",
    "print('\\n\\n')\n",
    "\n",
    "# print(torch.count_nonzero(sim.abs() >= 1e-2), sim.shape[0], sim.numel(), torch.count_nonzero(sim.abs() >= 1e-2) / sim.numel())\n",
    "vals, inds = torch.topk(sim2.abs(), k=10, dim=1)\n",
    "\n",
    "# print(inds[:4])\n",
    "# print(inds[:4].sum(1))\n",
    "# print(sim[sim < vals[:, -1].unsqueeze(1).expand(sim.shape)])\n",
    "sim2[sim2 < vals[:, -1]] *= 0\n",
    "# print(sim[:4, :4])\n",
    "\n",
    "\n",
    "# torch.linalg.det(uvh_1)\n",
    "\n",
    "# r = vh2 @ u1\n",
    "\n",
    "# sim_new = (r @ uvh_1).T @ uvh_avg\n",
    "# print(sim_new.diag()[:8])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-madonna-ddp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
