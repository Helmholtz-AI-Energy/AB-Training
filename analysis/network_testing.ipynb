{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!hostname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# import torchvision.models as models\n",
    "import torch.distributed as dist\n",
    "# import torch.optim as optim\n",
    "import scipy.stats as stats\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from rich.progress import track\n",
    "\n",
    "\n",
    "# # oialr_checkpoint_folder = \"/hkfs/work/workspace/scratch/qv2382-madonna/madonna/models/svd-final/12/weights/epoch_299.pt\"\n",
    "# oialr_checkpoint_folder = \"/hkfs/work/workspace/scratch/qv2382-madonna-ddp/madonna/models/svd-nodroppath/2/weights/epoch_299.pt\"\n",
    "# # baseline_checkpoint_folder = \"/hkfs/work/workspace/scratch/qv2382-madonna/madonna/models/baseline-final/8/weights/epoch_299.pt\"\n",
    "# baseline_checkpoint_folder = \"/hkfs/work/workspace/scratch/qv2382-madonna-ddp/madonna/models/baseline-nodroppath/1/weights/epoch_299.pt\"\n",
    "\n",
    "checkpoints = {}\n",
    "# ortho-sigma\n",
    "# /hkfs/work/workspace/scratch/qv2382-madonna-ddp/madonna/models/fed-debug/42/weights3\n",
    "# /hkfs/work/workspace/scratch/qv2382-madonna-ddp/madonna/models/fed-debug/42/weights2\n",
    "# /hkfs/work/workspace/scratch/qv2382-madonna-ddp/madonna/models/fed-debug/43/weights1\n",
    "# /hkfs/work/workspace/scratch/qv2382-madonna-ddp/madonna/models/fed-debug/44/weights0\n",
    "checkpoints[\"ortho-sigma\"] = {\n",
    "    0: Path(\"/hkfs/work/workspace/scratch/qv2382-madonna-ddp/madonna/models/fed-debug/44/weights0\"),\n",
    "    1: Path(\"/hkfs/work/workspace/scratch/qv2382-madonna-ddp/madonna/models/fed-debug/43/weights1\"),\n",
    "    2: Path(\"/hkfs/work/workspace/scratch/qv2382-madonna-ddp/madonna/models/fed-debug/42/weights2\"),\n",
    "    3: Path(\"/hkfs/work/workspace/scratch/qv2382-madonna-ddp/madonna/models/fed-debug/42/weights3\"),\n",
    "}\n",
    "\n",
    "checkpoints[\"rand-sigma\"] = {\n",
    "    0: Path(\"/hkfs/work/workspace/scratch/qv2382-madonna-ddp/madonna/models/fed-debug-randsigma/0/weights0\"),\n",
    "    1: Path(\"/hkfs/work/workspace/scratch/qv2382-madonna-ddp/madonna/models/fed-debug-randsigma/1/weights1\"),\n",
    "    2: Path(\"/hkfs/work/workspace/scratch/qv2382-madonna-ddp/madonna/models/fed-debug-randsigma/2/weights2\"),\n",
    "    3: Path(\"/hkfs/work/workspace/scratch/qv2382-madonna-ddp/madonna/models/fed-debug-randsigma/0/weights3\"),\n",
    "}\n",
    "\n",
    "checkpoints_resnet18 = {}\n",
    "checkpoints_resnet18[\"ortho-sigma\"] = {\n",
    "    # 1 : Path(\"/hkfs/work/workspace/scratch/qv2382-madonna-ddp/madonna/models/fed-orthosigma/13/weights1\"),\n",
    "    # 0: Path(\"/hkfs/work/workspace/scratch/qv2382-madonna-ddp/madonna/models/fed-orthosigma/13/weights0\"),\n",
    "    # 2: Path(\"/hkfs/work/workspace/scratch/qv2382-madonna-ddp/madonna/models/fed-orthosigma/13/weights2\"),\n",
    "    # 3: Path(\"/hkfs/work/workspace/scratch/qv2382-madonna-ddp/madonna/models/fed-orthosigma/13/weights3\"),\n",
    "    # 3: Path(\"/hkfs/work/workspace/scratch/qv2382-madonna-ddp/madonna/models/fed-orthosigma/9/weights3\"),\n",
    "    # 0: Path(\"/hkfs/work/workspace/scratch/qv2382-madonna-ddp/madonna/models/fed-orthosigma/10/weights0\"),\n",
    "    # 1: Path(\"/hkfs/work/workspace/scratch/qv2382-madonna-ddp/madonna/models/fed-orthosigma/11/weights1\"),\n",
    "    # 2: Path(\"/hkfs/work/workspace/scratch/qv2382-madonna-ddp/madonna/models/fed-orthosigma/12/weights2\"),\n",
    "    1: Path(\"/hkfs/work/workspace/scratch/qv2382-madonna-ddp/madonna/models/fed-orthosigma-2/1/weights1\"),\n",
    "    2: Path(\"/hkfs/work/workspace/scratch/qv2382-madonna-ddp/madonna/models/fed-orthosigma-2/2/weights2\"),\n",
    "    0: Path(\"/hkfs/work/workspace/scratch/qv2382-madonna-ddp/madonna/models/fed-orthosigma-2/3/weights0\"),\n",
    "    3: Path(\"/hkfs/work/workspace/scratch/qv2382-madonna-ddp/madonna/models/fed-orthosigma-2/4/weights3\"),\n",
    "}\n",
    "\n",
    "checkpoints_resnet18[\"rand-sigma\"] = {\n",
    "    3: Path(\"/hkfs/work/workspace/scratch/qv2382-madonna-ddp/madonna/models/fed-randsigma/0/weights3\"),\n",
    "    0: Path(\"/hkfs/work/workspace/scratch/qv2382-madonna-ddp/madonna/models/fed-randsigma/1/weights0\"),\n",
    "    2: Path(\"/hkfs/work/workspace/scratch/qv2382-madonna-ddp/madonna/models/fed-randsigma/2/weights2\"),\n",
    "    1: Path(\"/hkfs/work/workspace/scratch/qv2382-madonna-ddp/madonna/models/fed-randsigma/3/weights1\"),\n",
    "}\n",
    "checkpoints_resnet18[\"random\"] = {\n",
    "    3: Path(\"/hkfs/work/workspace/scratch/qv2382-madonna-ddp/madonna/models/fed-random/0/weights3\"),\n",
    "    0: Path(\"/hkfs/work/workspace/scratch/qv2382-madonna-ddp/madonna/models/fed-random/0/weights0\"),\n",
    "    2: Path(\"/hkfs/work/workspace/scratch/qv2382-madonna-ddp/madonna/models/fed-random/0/weights2\"),\n",
    "    1: Path(\"/hkfs/work/workspace/scratch/qv2382-madonna-ddp/madonna/models/fed-random/0/weights1\"),\n",
    "}\n",
    "\n",
    "checkpoints_resnet18[\"unified\"] = {\n",
    "    3: Path(\"/hkfs/work/workspace/scratch/qv2382-madonna-ddp/madonna/models/fed-unified/0/weights3\"),\n",
    "    0: Path(\"/hkfs/work/workspace/scratch/qv2382-madonna-ddp/madonna/models/fed-unified/1/weights0\"),\n",
    "    2: Path(\"/hkfs/work/workspace/scratch/qv2382-madonna-ddp/madonna/models/fed-unified/1/weights2\"),\n",
    "    1: Path(\"/hkfs/work/workspace/scratch/qv2382-madonna-ddp/madonna/models/fed-unified/1/weights1\"),\n",
    "}\n",
    "\n",
    "combos = [[0, 1], [0, 2], [0, 3], [1, 2], [1, 3], [2, 3]]\n",
    "epochs = [\"000\", \"024\", \"049\", \"074\", \"099\", \"124\", \"149\", \"174\", \"199\", \"224\", \"249\", \"274\", \"299\", ]  # \n",
    "\n",
    "# svd_model_dict = torch.load(oialr_checkpoint_folder, map_location=\"cpu\")\n",
    "# baseline_model_dict = torch.load(baseline_checkpoint_folder, map_location=\"cpu\")\n",
    "# print(list(baseline_model_dict[\"model\"].keys()))\n",
    "\n",
    "# get 2D reps for a checkpoint (fn)\n",
    "def get_2d_reps(model_dict, use_qr, float64=False):\n",
    "    ret_dict = {}\n",
    "    # nbytes = 0\n",
    "    for n in model_dict['model']:\n",
    "        p = model_dict['model'][n]\n",
    "        # print(n, p.shape, p.nbytes)\n",
    "        if p.ndim < 2:\n",
    "            continue\n",
    "\n",
    "        hld = p\n",
    "        shp = p.shape\n",
    "        if p.ndim > 2:  # collapse down to 2D\n",
    "            hld = p.view(p.shape[0], -1)\n",
    "        trans = hld.shape[0] < hld.shape[1]\n",
    "        if trans:  # make 2D rep TS\n",
    "            hld = hld.T\n",
    "\n",
    "        if float64:\n",
    "            hld = hld.to(torch.float64)\n",
    "        if not use_qr:\n",
    "            u, s, vh = torch.linalg.svd(hld, full_matrices=False)\n",
    "            ret_dict[n] = {'u': u, 's': s, 'vh': vh, 'trans': trans, \"w\": hld, \"shp\": shp}\n",
    "        else:\n",
    "            q, r = torch.linalg.qr(hld, mode=\"complete\")\n",
    "            ret_dict[n] = {'q': q, \"r\": r, 'trans': trans, \"w\": hld, \"shp\": shp}\n",
    "        \n",
    "    return ret_dict\n",
    "\n",
    "def get_2d_reps_from_names(model_dict, base_names, append_names, use_qr, float64=False):\n",
    "    ret_dict = {}\n",
    "    # nbytes = 0\n",
    "    for base in base_names:\n",
    "        p = model_dict['model'][base]\n",
    "        # print(base, p.shape, p.nbytes)\n",
    "        if p.ndim < 2:\n",
    "            continue\n",
    "\n",
    "        hld = p\n",
    "        shp = p.shape\n",
    "        if p.ndim > 2:  # collapse down to 2D\n",
    "            hld = p.view(p.shape[0], -1)\n",
    "        trans = hld.shape[0] < hld.shape[1]\n",
    "        if trans:  # make 2D rep TS\n",
    "            hld = hld.T\n",
    "\n",
    "        cat_dim = None\n",
    "\n",
    "        for app in append_names[base]:\n",
    "            app_p = model_dict['model'][app]\n",
    "            if cat_dim is None:\n",
    "                cat_dim = torch.nonzero(torch.tensor(hld.shape) == torch.tensor(app_p.shape)).flatten()[0].item()\n",
    "                # since its the same dim, need to cat it on the OTHER dim...\n",
    "                cat_dim = (cat_dim + 1) % 2\n",
    "            hld = torch.cat([hld, app_p.unsqueeze(cat_dim)], dim=cat_dim)\n",
    "\n",
    "        if float64:\n",
    "            hld = hld.to(torch.float64)\n",
    "\n",
    "        if not use_qr:\n",
    "            u, s, vh = torch.linalg.svd(hld, full_matrices=False)\n",
    "            ret_dict[base] = {'u': u, 's': s, 'vh': vh, 'trans': trans, \"w\": hld, \"cat_dim\": cat_dim, \"append_names\": append_names[base], \"shp\": shp}\n",
    "        else:\n",
    "            q, r = torch.linalg.qr(hld, mode=\"reduced\")\n",
    "            ret_dict[base] = {'q': q, \"r\": r, 'trans': trans, \"w\": hld, \"cat_dim\": cat_dim, \"append_names\": append_names[base], \"shp\": shp}\n",
    "    \n",
    "    return ret_dict\n",
    "\n",
    "def get_1d_associated_weights(model_dict):\n",
    "    wgts_to_join = {}\n",
    "    last_miltidim_w = None\n",
    "    ignore_list = []  # \"pos_embed\", \"cls_token\"\n",
    "    ignore_endings = (\"running_mean\", \"running_var\")\n",
    "    for n in model_dict[\"model\"]:\n",
    "        p = model_dict[\"model\"][n]\n",
    "        if n in ignore_list or n.endswith(ignore_endings):\n",
    "            continue\n",
    "        if p.ndim > 1:  # and last_miltidim_w is None:\n",
    "            last_miltidim_w = n\n",
    "            if n in wgts_to_join:\n",
    "                raise ValueError\n",
    "            wgts_to_join[n] = []\n",
    "        elif last_miltidim_w is not None and p.ndim == 1:\n",
    "            wgts_to_join[last_miltidim_w].append(n)\n",
    "    return wgts_to_join\n",
    "\n",
    "def merge_means_vars(inmodels: list, epoch: str):\n",
    "    # TODO: this will need to be parallized in a better way....heat-style?\n",
    "    # do a pairwise update of the means and vars in both \n",
    "    num_models = len(inmodels)\n",
    "    if num_models == 1:\n",
    "        raise ValueError(\"need multiple models for merging\")\n",
    "    # n0 = num_samples[epoch]\n",
    "    for layer in inmodels[0]:  # should be iterating over the layers now (TODO: DOUBLE CHECK)\n",
    "        # print(layer)\n",
    "        if not layer.endswith(\"mean\"):\n",
    "            continue\n",
    "        # only work on mean layers, get vars here as well (if they exist)\n",
    "        # go back and get the var tensor as well to update the batch norms\n",
    "        try: \n",
    "            var0 = inmodels[0][layer[:-4] + \"var\"]\n",
    "        except KeyError:\n",
    "            var0 = None\n",
    "        mu0 = inmodels[0][layer]\n",
    "        n0 = inmodels[0][layer[:-12] + \"num_batches_tracked\"]\n",
    "        # print(f\"{layer}: mu0: {mu0}\")\n",
    "        for ml in inmodels[1:]:\n",
    "            mul = ml[layer]\n",
    "            \n",
    "            nl = ml[layer[:-12] + \"num_batches_tracked\"]\n",
    "            n = nl + n0\n",
    "            delta = mul - mu0\n",
    "            mu = mu0 + nl * (delta / n)\n",
    "            # print(f\"{layer}: mu: {mu.mean():.4f} -> {mu0.mean():.4f} {mul.mean():.4f}\")\n",
    "            mu0.zero_()\n",
    "            mu0.add_(mu)\n",
    "\n",
    "            if var0 is not None:\n",
    "                varl = ml[layer[:-4] + \"var\"]\n",
    "                var_m = (var0 * (n0 - 1) + varl * (nl - 1) + (delta**2) * n0 * nl / n) / (n - 1)\n",
    "                # print(f\"{layer}: var: {var_m.mean():.4f} -> {var0.mean():.4f} {varl.mean():.4f}\")\n",
    "                var0.zero_()\n",
    "                var0.add_(var_m)\n",
    "            n0 = n\n",
    "        inmodels[0][layer[:-12] + \"num_batches_tracked\"] = n0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_models = True\n",
    "models = {}\n",
    "map_location = \"cuda:0\"  #\"gpu:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "if load_models:\n",
    "    for rank in range(4):\n",
    "        models[rank] = {}\n",
    "        for epoch in epochs:\n",
    "            models[rank][epoch] = torch.load(checkpoints_resnet18[\"ortho-sigma\"][rank] / f\"epoch_{epoch}.pt\", map_location=map_location)\n",
    "            # models[rank][epoch] = torch.load(checkpoints[\"ortho-sigma\"][rank] / f\"epoch_{epoch}.pt\", map_location=map_location)\n",
    "        print(f\"loaded models for rank: {rank}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rotation_btw_bases(basis_to_rotate, target_basis):\n",
    "    # TODO: rename basis_a -> to_rotate and basis_b -> target_basis\n",
    "    # create a rotation to rotate basis_a to basis_b\n",
    "    # returns: R so that R @ A == B\n",
    "\n",
    "    rot = torch.zeros((basis_to_rotate.shape[0], basis_to_rotate.shape[0]), dtype=basis_to_rotate.dtype, device=basis_to_rotate.device)\n",
    "    for col in range(basis_to_rotate.shape[1]):\n",
    "        rot += torch.kron(basis_to_rotate[:, col], target_basis[:, col].unsqueeze(1))\n",
    "    return rot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# is the rotation method the same as the average?\n",
    "r0combos = [1, 2, 3]\n",
    "cat_1d = True\n",
    "use_qr = False\n",
    "which_epoch = epochs[-1]\n",
    "float64 = False\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "# del model_0, rep_dict_0, rep_dict_l\n",
    "new_model_dict = OrderedDict()\n",
    "\n",
    "# if not load_models:\n",
    "#     model_0 = torch.load(checkpoints_resnet18[\"random\"][0] / f\"epoch_{which_epoch}.pt\", map_location=map_location)\n",
    "# else:\n",
    "model_0 = models[0][which_epoch]\n",
    "\n",
    "new_model_dict = model_0[\"model\"].copy()\n",
    "\n",
    "if cat_1d:\n",
    "    names = get_1d_associated_weights(model_0)\n",
    "    rep_dict_0 = get_2d_reps_from_names(model_dict=model_0, base_names=names.keys(), append_names=names, use_qr=use_qr, float64=float64)\n",
    "else:\n",
    "    rep_dict_0 = get_2d_reps(model_dict=model_0, use_qr=use_qr, float64=float64)\n",
    "\n",
    "for layer in rep_dict_0:  # create average of weights\n",
    "    rep_dict_0[layer]['w_avg'] = rep_dict_0[layer]['w'] / 4\n",
    "\n",
    "# get full Us and Vs\n",
    "for layer in rep_dict_0:\n",
    "    layer_0 = rep_dict_0[layer]\n",
    "    uf, _, vhf = torch.linalg.svd(layer_0['w'], full_matrices=True)\n",
    "    layer_0[\"uf\"] = uf\n",
    "    layer_0[\"vhf\"] = vhf\n",
    "\n",
    "for partner in r0combos:  # combos are 2d tuples with rankA, rankB\n",
    "    # getting results\n",
    "    # if not load_models:\n",
    "    #     model_l = torch.load(checkpoints[\"random\"][partner] / f\"epoch_{which_epoch}.pt\", map_location=map_location)\n",
    "    # else:\n",
    "    model_l = models[partner][which_epoch]\n",
    "        \n",
    "    # get append lists:\n",
    "    if cat_1d:\n",
    "        rep_dict_l = get_2d_reps_from_names(model_dict=model_l, base_names=names.keys(), append_names=names, use_qr=use_qr, float64=float64)\n",
    "    else:\n",
    "        rep_dict_l = get_2d_reps(model_dict=model_l, use_qr=use_qr, float64=float64)\n",
    "\n",
    "    # loop through the dict and move the \n",
    "    for layer in rep_dict_l:  # keys are the same\n",
    "        # do average here\n",
    "        rep_dict_0[layer]['w_avg'] += rep_dict_l[layer]['w'] / 4\n",
    "\n",
    "        layer_0 = rep_dict_0[layer]\n",
    "        layer_l = rep_dict_l[layer]\n",
    "        ufl, _, vhf = torch.linalg.svd(layer_l['w'], full_matrices=True)\n",
    "\n",
    "        u0 = layer_0['u']\n",
    "        uf0 = layer_0['uf']\n",
    "        ul = layer_l['u']\n",
    "        \n",
    "        v0 = layer_0['vh'].T\n",
    "        vf0 = layer_0['vhf'].T\n",
    "        vl = layer_l['vh'].T\n",
    "        vfl = vhf.T\n",
    "        ru = get_rotation_btw_bases(basis_to_rotate=u0.T, target_basis=ul.T)\n",
    "        rv = get_rotation_btw_bases(basis_to_rotate=v0.T, target_basis=vl.T)\n",
    "\n",
    "        sim = (u0 @ v0.T) @ (ul @ vl.T).T\n",
    "\n",
    "        if layer_0['s'].ndim == 1:\n",
    "            layer_0['s'] = layer_0['s'].diag()\n",
    "        layer_0['s'] += ru.T @ layer_l['s'].diag() @ rv\n",
    "        # layer_0['s'] += layer_l['s'].diag() @ sim\n",
    "        # print(partner, layer, layer_l['s'][:10])  \n",
    "        # layer_0['s'] += layer_l['s'].diag()\n",
    "        # layer_0['w'] += (sim @ layer_l['w']) / 4\n",
    "\n",
    "for layer in rep_dict_0:  # finish average of weights\n",
    "    u0, vh0 = rep_dict_0[layer]['u'], rep_dict_0[layer]['vh']\n",
    "    sig = rep_dict_0[layer]['s'] \n",
    "\n",
    "    w = (u0 @ sig @ vh0) / 4\n",
    "    w_avg = rep_dict_0[layer]['w_avg']\n",
    "    w = rep_dict_0[layer]['w']\n",
    "    # ua, sa, vha = torch.linalg.svd(w_avg, full_matrices=False)\n",
    "    # uw, sw, vhw = torch.linalg.svd(w, full_matrices=False)    \n",
    "    # print('avg sig', sa[:10])\n",
    "    # print('combi', sw[:10])\n",
    "\n",
    "    rep_dict_0[layer]['w_avg'] = w_avg\n",
    "    rep_dict_0[layer]['w'] = w\n",
    "    print(f\"w_avg: {layer}: {w_avg.mean():.5f} {w_avg.min():.5f} {w_avg.max():.5f} {w_avg.std():.5f} \")\n",
    "    print(f\"w: {layer}: {w.mean():.5f} {w.min():.5f} {w.max():.5f} {w.std():.5f} \")\n",
    "\n",
    "merge_means_vars(inmodels=[new_model_dict, *[models[i][which_epoch]['model'] for i in range(1, 4)]], epoch=which_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# undo 1D concat and add to new_model_dict\n",
    "avg_dict = {}\n",
    "\n",
    "for layer in list(rep_dict_0.keys()):\n",
    "    layer_dict = rep_dict_0[layer]\n",
    "\n",
    "    if \"cat_dim\" in layer_dict:\n",
    "        # this is the time to undo the cat-ing\n",
    "        sliced = 0\n",
    "        sl_dim = layer_dict[\"cat_dim\"]\n",
    "        for cat1dlayer in reversed(layer_dict[\"append_names\"]):  # have to work from outside in\n",
    "            # loop through the appended layers in revered order (outside -> in)\n",
    "            sliced += 1\n",
    "            sl = [slice(None), ] * layer_dict['w'].ndim\n",
    "            sl[sl_dim] = -sliced\n",
    "            # rep_dict_0[cat1dlayer] = {}\n",
    "            # rep_dict_0[cat1dlayer]['w'] = layer_dict['w'][sl].clone()\n",
    "            old_weight = new_model_dict[cat1dlayer]\n",
    "\n",
    "            weight = layer_dict['w'][sl].clone()\n",
    "            new_model_dict[cat1dlayer] = weight\n",
    "\n",
    "            avg_weight = layer_dict['w_avg'][sl].clone()\n",
    "            avg_dict[cat1dlayer] = avg_weight\n",
    "            \n",
    "            print(f\"old {cat1dlayer}, {old_weight.mean():.4f}, {old_weight.min():.4f}, {old_weight.max():.4f}, {old_weight.std():.4f}\")\n",
    "            print(f\"avg {cat1dlayer}, {avg_weight.mean():.4f}, {avg_weight.min():.4f}, {avg_weight.max():.4f}, {avg_weight.std():.4f}\")\n",
    "            print(f\"{cat1dlayer}, {weight.mean():.4f}, {weight.min():.4f}, {weight.max():.4f}, {weight.std():.4f}\")\n",
    "        # remove the last `sliced` layers from the weight matrix\n",
    "        sl = [slice(None), ] * layer_dict['w'].ndim\n",
    "        sl[sl_dim] = slice(-sliced)\n",
    "        weight = layer_dict['w'][sl]\n",
    "        avg_weight = layer_dict['w_avg'][sl]\n",
    "    else:\n",
    "        weight = layer_dict['w']\n",
    "        avg_weight = layer_dict['w_avg']\n",
    "\n",
    "    if layer_dict['trans']:\n",
    "        weight = weight.T\n",
    "        avg_weight = avg_weight.T\n",
    "\n",
    "    if weight.shape != layer_dict['shp']:\n",
    "        weight = weight.reshape(layer_dict['shp'])\n",
    "        avg_weight = avg_weight.reshape(layer_dict['shp'])\n",
    "    \n",
    "    old_weight = new_model_dict[layer]\n",
    "    avg_dict[layer] = avg_weight\n",
    "    new_model_dict[layer] = avg_weight.clone()\n",
    "\n",
    "    print(f\"old {layer}, {old_weight.mean():.4f}, {old_weight.min():.4f}, {old_weight.max():.4f}, {old_weight.std():.4f}\")\n",
    "    print(f\"avg {layer}, {avg_weight.mean():.4f}, {avg_weight.min():.4f}, {avg_weight.max():.4f}, {avg_weight.std():.4f}\")\n",
    "    print(f\"{layer}, {weight.mean():.4f}, {weight.min():.4f}, {weight.max():.4f}, {weight.std():.4f}\")\n",
    "    # print(layer, layer_dict['w'].shape)\n",
    "# for layer in rep_dict_0:\n",
    "#     print(layer, rep_dict_0[layer]['w'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normal average without anything else\n",
    "model_avg = models[0][which_epoch][\"model\"].copy()\n",
    "for lay in model_avg:\n",
    "    # print(lay)\n",
    "    for rank in range(1, 4):\n",
    "        model_avg[lay] += models[rank][which_epoch][\"model\"][lay]\n",
    "    if model_avg[lay].dtype == torch.long:\n",
    "        model_avg[lay] *= 4\n",
    "    else:\n",
    "        model_avg[lay] /= 4\n",
    "\n",
    "    if lay in new_model_dict:\n",
    "        print(f\"{lay}: comp to avg: {torch.allclose(model_avg[lay], new_model_dict[lay])} -> {(model_avg[lay] - new_model_dict[lay]).max()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set model weights\n",
    "import timm\n",
    "from timm.data.transforms_factory import create_transform\n",
    "\n",
    "model = timm.models.resnet18(num_classes=10)\n",
    "model = model.to(\"cuda:0\")\n",
    "model = model.float()\n",
    "with torch.no_grad():\n",
    "    # model.load_state_dict(models[0][\"299\"]['model'])\n",
    "    # model.load_state_dict(models[1][\"299\"][\"model\"])\n",
    "    model.load_state_dict(new_model_dict)\n",
    "    # model.load_state_dict(model_avg)\n",
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics import MetricCollection, Precision, Recall\n",
    "from torchmetrics.classification import MulticlassF1Score, MulticlassPrecision, MulticlassRecall\n",
    "\n",
    "device = \"cuda:0\"\n",
    "val_metrics = MetricCollection(\n",
    "    [\n",
    "        MulticlassF1Score(num_classes=10),\n",
    "        MulticlassPrecision(num_classes=10),\n",
    "        MulticlassRecall(num_classes=10),\n",
    "    ],\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "class Summary(Enum):\n",
    "    NONE = 0\n",
    "    AVERAGE = 1\n",
    "    SUM = 2\n",
    "    COUNT = 3\n",
    "\n",
    "\n",
    "class AverageMeter:\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "\n",
    "    def __init__(self, name, fmt=\":f\", summary_type=Summary.AVERAGE, pg=None):\n",
    "        self.name = name\n",
    "        self.fmt = fmt\n",
    "        self.summary_type = summary_type\n",
    "        self.reset()\n",
    "        self.pg = pg\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "    def all_reduce(self):\n",
    "        if torch.cuda.is_available():\n",
    "            device = torch.device(\"cuda\")\n",
    "        elif torch.backends.mps.is_available():\n",
    "            device = torch.device(\"mps\")\n",
    "        else:\n",
    "            device = torch.device(\"cpu\")\n",
    "        total = torch.tensor([self.sum, self.count], dtype=torch.float32, device=device)\n",
    "        dist.all_reduce(total, dist.ReduceOp.SUM, async_op=False, group=self.pg)\n",
    "        self.sum, self.count = total.tolist()\n",
    "        # self.avg = self.sum / self.count\n",
    "        self.avg = total[0] / total[1]  # self.sum / self.count\n",
    "\n",
    "    def __str__(self):\n",
    "        fmtstr = \"{name} {val\" + self.fmt + \"} ({avg\" + self.fmt + \"})\"\n",
    "        return fmtstr.format(**self.__dict__)\n",
    "\n",
    "    def summary(self):\n",
    "        # fmtstr = \"\"\n",
    "        if self.summary_type is Summary.NONE:\n",
    "            fmtstr = \"\"\n",
    "        elif self.summary_type is Summary.AVERAGE:\n",
    "            fmtstr = \"{name} {avg:.3f}\"\n",
    "        elif self.summary_type is Summary.SUM:\n",
    "            fmtstr = \"{name} {sum:.3f}\"\n",
    "        elif self.summary_type is Summary.COUNT:\n",
    "            fmtstr = \"{name} {count:.3f}\"\n",
    "        else:\n",
    "            raise ValueError(\"invalid summary type %r\" % self.summary_type)\n",
    "\n",
    "        return fmtstr.format(**self.__dict__)\n",
    "\n",
    "\n",
    "class ProgressMeter:\n",
    "    def __init__(self, num_batches, meters, prefix=\"\"):\n",
    "        self.batch_fmtstr = self._get_batch_fmtstr(num_batches)\n",
    "        self.meters = meters\n",
    "        self.prefix = prefix\n",
    "        self.rank = 0 if not dist.is_initialized() else dist.get_rank()\n",
    "\n",
    "    def display(self, batch, log=None):\n",
    "        entries = [self.prefix + self.batch_fmtstr.format(batch)]\n",
    "        entries += [str(meter) for meter in self.meters]\n",
    "        # if self.rank == 0:\n",
    "        #     # log.info(\"\\t\".join(entries))\n",
    "        if log is None:\n",
    "            print(\" \".join(entries))\n",
    "        else:\n",
    "            log.info(\" \".join(entries))\n",
    "\n",
    "    def display_summary(self, log=None, printing_rank=None):\n",
    "        entries = [\" *\"]\n",
    "        entries += [meter.summary() for meter in self.meters]\n",
    "        if printing_rank or printing_rank is None:\n",
    "            if log is None:\n",
    "                print(\" \".join(entries))\n",
    "            else:\n",
    "                # console.print(\" \".join(entries))\n",
    "                log.info(\" \".join(entries))\n",
    "\n",
    "    def _get_batch_fmtstr(self, num_batches):\n",
    "        num_digits = len(str(num_batches // 1))\n",
    "        fmt = \"{:\" + str(num_digits) + \"d}\"\n",
    "        return \"[\" + fmt + \"/\" + fmt.format(num_batches) + \"]\"\n",
    "\n",
    "\n",
    "def accuracy(output, target, topk=(1,), mixup=False):\n",
    "    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
    "    with torch.no_grad():\n",
    "        maxk = max(topk)\n",
    "        batch_size = target.size(0)\n",
    "\n",
    "        _, pred = output.topk(maxk, 1, True, True)\n",
    "        if not mixup:\n",
    "            pred = pred.t()\n",
    "            correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "            res = []\n",
    "            for k in topk:\n",
    "                correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
    "                res.append(correct_k.mul_(100.0 / batch_size))\n",
    "            return res\n",
    "        else:\n",
    "            maxk = max(topk)\n",
    "            batch_size = target.size(0)\n",
    "            if target.ndim == 2:\n",
    "                target = target.max(dim=1)[1]\n",
    "\n",
    "            _, pred = output.topk(maxk, 1, True, True)\n",
    "            pred = pred.t()\n",
    "            correct = pred.eq(target[None])\n",
    "\n",
    "            res = []\n",
    "            for k in topk:\n",
    "                correct_k = correct[:k].flatten().sum(dtype=torch.float32)\n",
    "                res.append(correct_k * (100.0 / batch_size))\n",
    "            return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "\n",
    "def run_validate(loader, base_progress=0):\n",
    "    # rank = 0 if not dist.is_initialized() else dist.get_rank()\n",
    "    with torch.no_grad():\n",
    "        end = time.time()\n",
    "        num_elem = len(loader) - 1\n",
    "        for i, data in enumerate(loader):\n",
    "            \n",
    "            images = data[0]\n",
    "            target = data[1]\n",
    "            i = base_progress + i\n",
    "            images = images.to(device, non_blocking=True)\n",
    "            target = target.to(device, non_blocking=True)\n",
    "\n",
    "            data_time.update(time.time() - end)\n",
    "\n",
    "            if torch.any(torch.isnan(images)):\n",
    "                # for n, p in model.named_parameters():\n",
    "                # print(f\"{n}: {p.mean():.4f}, {p.min():.4f}, {p.max():.4f}, {p.std():.4f}\")\n",
    "                raise ValueError(\"NaN in images... - VAL\")\n",
    "\n",
    "            # compute output\n",
    "            output = model(images)\n",
    "            loss = criterion(output, target)\n",
    "            # argmax = torch.argmax(output.output, dim=1).to(torch.float32)\n",
    "\n",
    "            # measure accuracy and record loss\n",
    "            acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
    "            losses.update(loss.item(), images.size(0))\n",
    "            top1.update(acc1[0], images.size(0))\n",
    "            top5.update(acc5[0], images.size(0))\n",
    "            val_metrics.update(output, target)\n",
    "\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "            # print(output[0])\n",
    "            if not torch.isfinite(loss):\n",
    "                # for n, p in model.named_parameters():\n",
    "                for n, p in model.named_parameters():\n",
    "                    print(f\"{n}: {p.mean():.4f}, {p.min():.4f}, {p.max():.4f}, {p.std():.4f}, {torch.any(torch.isfinite(p))}\")\n",
    "                raise ValueError(\"NaN loss - VAL\")\n",
    "            if (i % 50 == 0 or i == num_elem):\n",
    "                argmax = torch.argmax(output, dim=1).to(torch.float32)\n",
    "                print(\n",
    "                    f\"output mean: {argmax.mean().item()}, max: {argmax.max().item()}, \",\n",
    "                    f\"min: {argmax.min().item()}, std: {argmax.std().item()}\",\n",
    "                )\n",
    "                progress.display(i + 1)\n",
    "            # return\n",
    "\n",
    "batch_time = AverageMeter(\"Time\", \":6.3f\", Summary.NONE)\n",
    "data_time = AverageMeter(\"Data\", \":6.3f\", Summary.NONE)\n",
    "losses = AverageMeter(\"Loss\", \":.4f\", Summary.AVERAGE)\n",
    "top1 = AverageMeter(\"Acc@1\", \":6.2f\", Summary.AVERAGE)\n",
    "top5 = AverageMeter(\"Acc@5\", \":6.2f\", Summary.AVERAGE)\n",
    "progress = ProgressMeter(\n",
    "    len(test_loader) + (len(test_loader.sampler) < len(test_loader.dataset)),\n",
    "    [batch_time, losses, top1, top5],\n",
    "    prefix=\"Test: \",\n",
    ")\n",
    "\n",
    "# switch to evaluate mode\n",
    "model.eval()\n",
    "vt1 = time.perf_counter()\n",
    "run_validate(test_loader)\n",
    "\n",
    "if len(test_loader.sampler) < len(test_loader.dataset):\n",
    "    aux_val_dataset = Subset(\n",
    "        test_loader.dataset,\n",
    "        range(len(test_loader.sampler), len(test_loader.dataset)),\n",
    "    )\n",
    "    aux_val_loader = torch.utils.data.DataLoader(\n",
    "        aux_val_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=6,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "    run_validate(aux_val_loader, len(test_loader))\n",
    "val_time_total = time.perf_counter() - vt1\n",
    "\n",
    "progress.display_summary()\n",
    "\n",
    "print(top1.avg, losses.avg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchtest",
   "language": "python",
   "name": "torchtest"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
